# üöÄ Gu√≠a de Despliegue a Producci√≥n

Esta gu√≠a explica c√≥mo desplegar **Ticket Triage Copilot** a producci√≥n usando diferentes plataformas.

---

## üìã Prerrequisitos

1. **Cuenta en plataforma de despliegue** (Vercel, Render, etc.)
2. **Repositorio Git** (GitHub, GitLab, Bitbucket)
3. **OpenAI API Key** (opcional, pero recomendado)

---

## üåê Opci√≥n 1: Vercel (Recomendado)

### Pasos:

1. **Instalar Vercel CLI** (opcional, tambi√©n puedes usar la web):
   ```bash
   npm i -g vercel
   ```

2. **Login en Vercel**:
   ```bash
   vercel login
   ```

3. **Desplegar**:
   ```bash
   vercel --prod
   ```

   O desde la web de Vercel:
   - Conecta tu repositorio
   - Vercel detectar√° autom√°ticamente `vercel.json`
   - Configura variables de entorno (ver abajo)

### Variables de Entorno en Vercel:

Ve a **Settings ‚Üí Environment Variables** y a√±ade:

```
OPENAI_API_KEY=sk-tu-api-key-aqui (opcional)
OPENAI_MODEL=gpt-4o-mini
FRONTEND_ORIGIN=*
```

### Estructura para Vercel:

- ‚úÖ `vercel.json` configurado
- ‚úÖ `api/index.js` como handler serverless
- ‚úÖ Archivos est√°ticos en `public/`

### URL despu√©s del despliegue:

Vercel te proporcionar√° una URL como:
```
https://tu-proyecto.vercel.app
```

---

## üñ•Ô∏è Opci√≥n 2: Render

### Pasos:

1. **Crear cuenta en Render**: https://render.com

2. **Nuevo Web Service**:
   - Conecta tu repositorio
   - Render detectar√° `render.yaml`
   - O configura manualmente:
     - **Build Command**: `npm install && npm run ingest`
     - **Start Command**: `node src/server.mjs`
     - **Environment**: `Node`

3. **Variables de Entorno**:
   ```
   NODE_ENV=production
   PORT=10000
   OPENAI_API_KEY=sk-tu-api-key (opcional)
   OPENAI_MODEL=gpt-4o-mini
   FRONTEND_ORIGIN=*
   ```

4. **Desplegar**:
   - Render desplegar√° autom√°ticamente
   - La URL ser√°: `https://tu-proyecto.onrender.com`

---

## üê≥ Opci√≥n 3: Docker (Cualquier plataforma)

### Crear Dockerfile:

```dockerfile
FROM node:18-alpine

WORKDIR /app

COPY package*.json ./
RUN npm ci --only=production

COPY . .

RUN npm run ingest

EXPOSE 4000

ENV NODE_ENV=production
ENV PORT=4000

CMD ["node", "src/server.mjs"]
```

### Construir y ejecutar:

```bash
docker build -t ticket-triage-copilot .
docker run -p 4000:4000 -e OPENAI_API_KEY=sk-... ticket-triage-copilot
```

---

## ‚öôÔ∏è Variables de Entorno

### Requeridas:
- Ninguna (el sistema funciona sin OpenAI API key usando heur√≠sticas)

### Opcionales pero recomendadas:
- `OPENAI_API_KEY`: Tu API key de OpenAI (para usar IA real)
- `OPENAI_MODEL`: Modelo a usar (default: `gpt-4o-mini`)
- `PORT`: Puerto del servidor (default: `4000`)
- `FRONTEND_ORIGIN`: Origen permitido para CORS (default: `*`)

---

## ‚úÖ Verificaci√≥n Post-Despliegue

### 1. Health Check:
```bash
curl https://tu-url.com/health
```
Deber√≠a responder: `{"ok":true,"timestamp":"..."}`

### 2. Probar API de Clientes:
```bash
curl https://tu-url.com/api/clients
```
Deber√≠a devolver lista de 10 clientes.

### 3. Probar Clasificaci√≥n:
```bash
curl -X POST https://tu-url.com/api/tickets \
  -H "Content-Type: application/json" \
  -d '{
    "title": "Error cr√≠tico",
    "description": "Sistema ca√≠do",
    "client": "TechFin Solutions"
  }'
```

### 4. Probar Frontend:
Abre `https://tu-url.com` en el navegador y verifica:
- ‚úÖ Formulario carga correctamente
- ‚úÖ Selector de clientes funciona
- ‚úÖ Clasificaci√≥n de tickets funciona
- ‚úÖ Feedback loop funciona

---

## üîß Soluci√≥n de Problemas

### Error: "Cannot find module"
- Verifica que `npm run ingest` se ejecute en el build
- Aseg√∫rate de que `data/rag_corpus.json` existe

### Error: "CORS"
- Verifica `FRONTEND_ORIGIN` en variables de entorno
- Aseg√∫rate de que el frontend use la URL correcta

### Error: "OpenAI API"
- Si no tienes API key, el sistema usar√° heur√≠sticas (funciona igual)
- Si quieres usar IA, a√±ade `OPENAI_API_KEY` en variables de entorno

### Archivos est√°ticos no cargan
- Verifica que `public/` est√© incluido en el despliegue
- En Vercel, `vercel.json` maneja esto autom√°ticamente

---

## üìä Monitoreo

### Logs:
- **Vercel**: Dashboard ‚Üí Logs
- **Render**: Dashboard ‚Üí Logs
- **Docker**: `docker logs <container-id>`

### M√©tricas a monitorear:
- Tiempo de respuesta de `/api/tickets`
- Uso de tokens de OpenAI (si aplica)
- Errores 500
- Tasa de √©xito de clasificaciones

---

## üîÑ Actualizaciones

### Desplegar cambios:

**Vercel**:
```bash
git push origin main
# Vercel desplegar√° autom√°ticamente
```

**Render**:
- Push a `main` ‚Üí Auto-deploy
- O manualmente desde dashboard

**Docker**:
```bash
docker build -t ticket-triage-copilot .
docker push <registry>/ticket-triage-copilot
```

---

## üí∞ Costos Estimados

### Vercel:
- **Hobby (Gratis)**: 100GB bandwidth/mes, suficiente para pruebas
- **Pro**: $20/mes (si necesitas m√°s recursos)

### Render:
- **Free Tier**: 750 horas/mes (suficiente para desarrollo)
- **Starter**: $7/mes (para producci√≥n)

### OpenAI:
- **gpt-4o-mini**: ~$0.0001 por ticket
- **1000 tickets/mes**: ~$0.10/mes

---

## ‚úÖ Checklist de Despliegue

- [ ] Repositorio en Git
- [ ] Variables de entorno configuradas
- [ ] `npm run ingest` ejecutado (o en build)
- [ ] Health check responde OK
- [ ] API de clientes funciona
- [ ] Clasificaci√≥n de tickets funciona
- [ ] Frontend carga correctamente
- [ ] Feedback loop funciona
- [ ] CORS configurado correctamente

---

## üéâ ¬°Listo!

Una vez desplegado, tu sistema estar√° disponible p√∫blicamente y podr√°s:
- Compartir la URL con evaluadores
- Grabar el video demostrativo
- Usar el sistema en producci√≥n

**URL de ejemplo**: `https://ticket-triage-copilot.vercel.app`

---

¬øNecesitas ayuda? Revisa los logs de la plataforma o consulta la documentaci√≥n t√©cnica en `docs/TECNICO.md`.

